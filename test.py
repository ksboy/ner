# label_ids 11
# input_ids = ntokens 12
# valid 12

# from transformers import AutoModel, AutoTokenizer, BertTokenizer
# model = AutoModel.from_pretrained('twmkn9/bert-base-uncased-squad2', mirror='https://mirrors.tuna.tsinghua.edu.cn/hugging-face-models')
# ishan/bert-base-uncased-mnli
# twmkn9/bert-base-uncased-squad2
# deepset/bert-large-uncased-whole-word-masking-squad2
# tokenizer = BertTokenizer.from_pretrained("/home/whou/workspace/pretrained_models/bert-base-cased")
# print(tokenizer.tokenize("BRUSSELS"))
# from seqeval.metrics.sequence_labeling import get_entities
# entities = get_entities(['B-PER', 'I-LOC', 'O', 'B-LOC'])
# print(entities)